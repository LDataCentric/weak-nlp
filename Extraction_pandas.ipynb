{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"sample_data/extraction.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e52281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weak_nlp\n",
    "from weak_nlp import extraction\n",
    "\n",
    "\n",
    "def get_enlm_from_df(df):\n",
    "    vectors = []\n",
    "    for source_id, df_sub_source in df.fillna(\"manual\").groupby(\"source_id\"):\n",
    "        associations = []\n",
    "        for (record_id, label_id), df_sub_source_record_label in df_sub_source.groupby(\n",
    "            [\"record_id\", \"label_id\"]\n",
    "        ):\n",
    "            max_token = max(df_sub_source_record_label.token_index)\n",
    "            min_token = min(df_sub_source_record_label.token_index)\n",
    "            confidence = df_sub_source_record_label.confidence.iloc[0]\n",
    "            associations.append(\n",
    "                extraction.ExtractionAssociation(\n",
    "                    record_id,\n",
    "                    label_id,\n",
    "                    min_token,\n",
    "                    max_token,\n",
    "                    confidence=confidence,\n",
    "                )\n",
    "            )\n",
    "        vectors.append(\n",
    "            weak_nlp.SourceVector(source_id, source_id == \"manual\", associations)\n",
    "        )\n",
    "\n",
    "    return extraction.ENLM(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca993cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enlm = get_enlm_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enlm.quality_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8956d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "enlm.quantity_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_ = enlm.vectors_noisy[0]\n",
    "enlm_ = extraction.ENLM([enlm.vector_reference, vector_])\n",
    "enlm_ = enlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weak_nlp.extraction import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reference = enlm_.vector_reference.associations\n",
    "df_reference_flat = util.flatten_range_df(df_reference, include_source=False)\n",
    "\n",
    "reference_labels = list(df_reference[\"label\"].dropna().unique())\n",
    "for idx, vector_noisy in enumerate(enlm_.vectors_noisy):\n",
    "    quality = {}\n",
    "    df_noisy = vector_noisy.associations\n",
    "    df_noisy_flat = util.flatten_range_df(df_noisy, include_source=False)\n",
    "    \n",
    "    break\n",
    "\n",
    "    noisy_labels = list(vector_noisy.associations[\"label\"].dropna().unique())\n",
    "    for label_name in noisy_labels + reference_labels:\n",
    "        quality[label_name] = {\n",
    "            \"true_positives\": 0,\n",
    "            \"false_positives\": 0,\n",
    "            \"false_negatives\": 0,\n",
    "        }\n",
    "\n",
    "    for (record, label), df_reference_sub_record_label in df_reference.groupby(\n",
    "        [\"record\", \"label\"]\n",
    "    ):\n",
    "        token_set_reference = util.get_token_range(\n",
    "            df_reference_sub_record_label\n",
    "        )\n",
    "\n",
    "        df_noisy_sub_record_label = df_noisy.loc[\n",
    "            (df_noisy[\"record\"] == record) & (df_noisy[\"label\"] == label)\n",
    "        ].copy()\n",
    "\n",
    "        if len(df_noisy_sub_record_label) > 0:\n",
    "            token_set_noisy = util.get_token_range(df_noisy_sub_record_label)\n",
    "\n",
    "            tps = len(token_set_reference.intersection(token_set_noisy))\n",
    "            fps = len(token_set_noisy.difference(token_set_reference))\n",
    "            fns = len(token_set_reference.difference(token_set_noisy))\n",
    "        else:\n",
    "            tps = 0\n",
    "            fps = 0\n",
    "            fns = len(token_set_reference)\n",
    "\n",
    "        quality[label][\"true_positives\"] += tps\n",
    "        quality[label][\"false_positives\"] += fps\n",
    "        quality[label][\"false_negatives\"] += fns\n",
    "    enlm_.vectors_noisy[idx].quality = quality.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d90cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8f0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ce614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd43c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1779f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_by_token = df_reference_flat.set_index(\"record\").join(df_noisy_flat.set_index(\"record\"), how=\"outer\", lsuffix=\"_reference\", rsuffix=\"_noisy\")\n",
    "\n",
    "true_positives = df_joined_by_token.loc[df_joined_by_token[\"label_reference\"] == df_joined_by_token[\"label_noisy\"]]\n",
    "both_negatives = df_joined_by_token.loc[df_joined_by_token[\"label_reference\"] != df_joined_by_token[\"label_noisy\"]].dropna()\n",
    "false_positives = df_joined_by_token.loc[df_joined_by_token[\"label_reference\"].isnull()]\n",
    "false_negatives = df_joined_by_token.loc[df_joined_by_token[\"label_noisy\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = {label: {\n",
    "    \"true_positives\": 0,\n",
    "    \"false_positives\": 0,\n",
    "    \"false_negatives\": 0\n",
    "} for label in reference_labels + noisy_labels}\n",
    "\n",
    "for label, tp_sub_label in true_positives.groupby(\"label_reference\"):\n",
    "    quality[label][\"true_positives\"] += len(tp_sub_label)\n",
    "    \n",
    "for label, fn_sub_label in both_negatives.groupby(\"label_reference\"):\n",
    "    quality[label][\"false_negatives\"] += len(fn_sub_label)\n",
    "    \n",
    "for label, fn_sub_label in false_negatives.groupby(\"label_reference\"):\n",
    "    quality[label][\"false_negatives\"] += len(fn_sub_label)\n",
    "    \n",
    "for label, fp_sub_label in both_negatives.groupby(\"label_noisy\"):\n",
    "    quality[label][\"false_positives\"] += len(fp_sub_label)\n",
    "    \n",
    "for label, fp_sub_label in false_positives.groupby(\"label_noisy\"):\n",
    "    quality[label][\"false_positives\"] += len(fp_sub_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
